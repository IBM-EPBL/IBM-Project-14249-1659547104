{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07fd92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad214eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainPath=\"F:\\IBM\\TRAIN_SET\"\n",
    "destPath=\"F:\\IBM\\DEST\"\n",
    "    \n",
    "\n",
    "im_size = 224\n",
    "rangeLower=0\n",
    "rangeUpper=100\n",
    "imgsInFile=30\n",
    "startFileCount=0\n",
    "augmentCount=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c400a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "apples=995\n",
    "b=1374\n",
    "o=1019\n",
    "pa=275\n",
    "wm=475\n",
    "\n",
    "classId=[\"APPLES\",\"BANANA\",\"ORANGE\",\"PINEAPPLE\",\"WATERMELON\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a67adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetV2S\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "\n",
    "inputs = layers.Input(shape=(im_size, im_size, 3))\n",
    "size = (im_size, im_size)\n",
    "\n",
    "noOfClasses = 5\n",
    "imgCategory=np.array([i for i in range(noOfClasses)])\n",
    "inputImg=[]\n",
    "imgLabels=[]\n",
    "\n",
    "    \n",
    "for i in range(len(classId)):\n",
    "    dirPath=mainPath+\"\\\\\"+str(classId[i])\n",
    "    cnt=0\n",
    "    for j in os.listdir(dirPath): \n",
    "        ImgPath=mainPath+\"\\\\\"+str(classId[i])+\"\\\\\"+j \n",
    "        image = cv2.imread(ImgPath)       \n",
    "        if(image is not None):\n",
    "            #BGR->RGB\n",
    "            img2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            img3 = cv2.resize(img2, (im_size, im_size))\n",
    "            img3 = img3.astype('float32') / 255.0       \n",
    "            inputImg.append(img3)\n",
    "            imgLabels=imgLabels+[i]\n",
    "        cnt+=1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3acedccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "...  ..\n",
      "4133  4\n",
      "4134  4\n",
      "4135  4\n",
      "4136  4\n",
      "4137  4\n",
      "\n",
      "[4138 rows x 1 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#data=np.array(inputImg[:60]+inputImg[apples:apples+60]+inputImg[apples+b:apples+b+60]+inputImg[apples+b+o:apples+b+o+60]+inputImg[apples+b+o+pa:apples+b+o+pa+60])\n",
    "#labels=np.array(imgLabels[:60]+imgLabels[apples:apples+60]+imgLabels[apples+b:apples+b+60]+imgLabels[apples+b+o:apples+b+o+60]+imgLabels[apples+b+o+pa:apples+b+o+pa+60])\n",
    "data=np.array(inputImg)\n",
    "labels=np.array(imgLabels)\n",
    "df = pd.DataFrame(labels,columns=[\"A\"])\n",
    "\n",
    "print(df)\n",
    "print(type(df))\n",
    "one_hot_encoded_data = pd.get_dummies(df,columns=[\"A\"]).to_numpy()\n",
    "print(one_hot_encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b520ec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4138, 224, 224, 3)\n",
      "(4138,)\n",
      "622884864\n",
      "4138\n",
      "4138\n",
      "4138\n",
      "(4138, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "print(data.size)\n",
    "print(labels.size)\n",
    "print(len(inputImg))\n",
    "print(len(imgLabels))\n",
    "print(one_hot_encoded_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b462f853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 5)                2264389   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,264,389\n",
      "Trainable params: 2,230,277\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "138/138 [==============================] - 356s 3s/step - loss: 0.5881 - accuracy: 0.7948\n",
      "Epoch 2/5\n",
      "138/138 [==============================] - 352s 3s/step - loss: 0.3108 - accuracy: 0.8881\n",
      "Epoch 3/5\n",
      "138/138 [==============================] - 346s 3s/step - loss: 0.2590 - accuracy: 0.9113\n",
      "Epoch 4/5\n",
      "138/138 [==============================] - 346s 3s/step - loss: 0.2216 - accuracy: 0.9203\n",
      "Epoch 5/5\n",
      "138/138 [==============================] - 341s 2s/step - loss: 0.2260 - accuracy: 0.9200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22897974f40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=True, weights=None, classes=noOfClasses)(inputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"] )\n",
    "model.summary()\n",
    "model.fit(data, one_hot_encoded_data,shuffle=True, epochs=5, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13d0b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(os.path.exists('./WeightsDir2')):\n",
    "    os.makedirs('./WeightsDir2')\n",
    "model.save_weights('./WeightsDir2/weights')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec7c6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "testApples=266\n",
    "testBanana=415\n",
    "testOrange=248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79e6726f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLES', 'BANANA', 'ORANGE']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"F:\\IBM\\TEST_SET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31312b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPath=\"F:\\IBM\\TEST_SET\"\n",
    "inputImgT=[]\n",
    "imgLabelsT=[]\n",
    "\n",
    "tClassId=[\"APPLES\",\"BANANA\",\"ORANGE\"]\n",
    "\n",
    "for i in range(3):\n",
    "    dirPath=testPath+\"\\\\\"+str(tClassId[i])\n",
    "    #print(dirPath)\n",
    "    cnt=0\n",
    "    #F:\\IBM\\TEST_SET\\APPLES\n",
    "    for j in os.listdir(dirPath): \n",
    "        ImgPath=dirPath+\"\\\\\"+j \n",
    "        image = cv2.imread(ImgPath)     \n",
    "        #print(ImgPath)\n",
    "        if(image is not None):\n",
    "            #BGR->RGB\n",
    "            img2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            img3 = cv2.resize(img2, (im_size, im_size))\n",
    "            img3 = img3.astype('float32') / 255.0       \n",
    "            inputImgT.append(img3)\n",
    "            imgLabelsT=imgLabelsT+[i]\n",
    "        cnt+=1\n",
    "    #print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bd9eb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929\n",
      "929\n"
     ]
    }
   ],
   "source": [
    "print(len(inputImgT))\n",
    "print(len(imgLabelsT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59a50724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929, 224, 224, 3)\n",
      "(931,)\n"
     ]
    }
   ],
   "source": [
    "dataT=np.array(inputImgT)\n",
    "labelsT=np.array(imgLabelsT+[3,4])\n",
    "print(dataT.shape)\n",
    "print(labelsT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "023adb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "..  ..\n",
      "926  2\n",
      "927  2\n",
      "928  2\n",
      "929  3\n",
      "930  4\n",
      "\n",
      "[931 rows x 1 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " ...\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "dfT = pd.DataFrame(labelsT,columns=[\"A\"])\n",
    "print(dfT)\n",
    "print(type(dfT))\n",
    "one_hot_encoded_dataT = pd.get_dummies(dfT,columns=[\"A\"]).to_numpy()\n",
    "one_hot_encoded_dataT = one_hot_encoded_dataT[:-2]\n",
    "print(one_hot_encoded_dataT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1d59a06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 12s 537ms/step - loss: 2.0250 - accuracy: 0.5693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.025041103363037, 0.5692729949951172]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(dataT)\n",
    "model.evaluate(dataT,one_hot_encoded_dataT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb209c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
